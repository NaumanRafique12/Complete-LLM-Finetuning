{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BtXGqeLLxDjU"
      },
      "outputs": [],
      "source": [
        "!pip install torch torchvision torchaudio xformers --index-url https://download.pytorch.org/whl/cu128\n",
        "!pip install unsloth\n",
        "!pip install transformers==4.56.2\n",
        "!pip install --no-deps trl==0.22.2\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    model_name=\"unsloth/tinyllama-bnb-4bit\",\n",
        "    max_seq_length=4096,\n",
        "    dtype=None,\n",
        "    load_in_4bit=True,\n",
        ")\n"
      ],
      "metadata": {
        "id": "3aeY2ZWHxElU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = FastLanguageModel.get_peft_model(\n",
        "    model,\n",
        "    r=32,\n",
        "    target_modules=[...],\n",
        "    lora_alpha=32,\n",
        "    lora_dropout=0,\n",
        "    bias=\"none\",\n",
        "    use_gradient_checkpointing=False,\n",
        ")\n"
      ],
      "metadata": {
        "id": "VkOwrAjRxGqK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "alpaca_prompt = \"\"\"...\"\"\"\n",
        "EOS_TOKEN = tokenizer.eos_token\n"
      ],
      "metadata": {
        "id": "oQrbUNlbxJMB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = SFTTrainer(\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    train_dataset=dataset,\n",
        "    packing=True,\n",
        "    args=SFTConfig(\n",
        "        per_device_train_batch_size=2,\n",
        "        gradient_accumulation_steps=4,\n",
        "        num_train_epochs=1,\n",
        "        learning_rate=2e-5,\n",
        "        optim=\"adamw_8bit\",\n",
        "    ),\n",
        ")\n"
      ],
      "metadata": {
        "id": "PsA9yQBbxKhp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.max_memory_reserved()\n"
      ],
      "metadata": {
        "id": "0AYwJp-ixM-p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "FastLanguageModel.for_inference(model)\n"
      ],
      "metadata": {
        "id": "NABZTWVRxNjD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_pretrained(\"lora_model\")\n",
        "tokenizer.save_pretrained(\"lora_model\")\n"
      ],
      "metadata": {
        "id": "TJGixF1AxPYC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "FastLanguageModel.from_pretrained(\"lora_model\")\n"
      ],
      "metadata": {
        "id": "-YoYxX96xRgX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_pretrained_merged(..., save_method=\"merged_16bit\")\n"
      ],
      "metadata": {
        "id": "TPiHdrw0xTG9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_pretrained_gguf(..., quantization_method=\"q4_k_m\")\n"
      ],
      "metadata": {
        "id": "1nZxGTtexU1I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.to(\"cuda\")\n"
      ],
      "metadata": {
        "id": "hk27jUzrxXAe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seed=3407\n"
      ],
      "metadata": {
        "id": "jWtsvwmBxYNS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_steps = 100\n",
        "num_train_epochs = None\n"
      ],
      "metadata": {
        "id": "lJwN4sflxZVD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# 1. Imports & Config\n",
        "# =========================\n",
        "from unsloth import FastLanguageModel\n",
        "from datasets import load_dataset\n",
        "from trl import SFTTrainer, SFTConfig\n",
        "import torch\n",
        "\n",
        "max_seq_length = 4096\n",
        "dtype = None\n",
        "load_in_4bit = True\n"
      ],
      "metadata": {
        "id": "aHl8b3JBxdzp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# 2. Load Model (4-bit)\n",
        "# =========================\n",
        "model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    model_name=\"unsloth/tinyllama-bnb-4bit\",\n",
        "    max_seq_length=max_seq_length,\n",
        "    dtype=dtype,\n",
        "    load_in_4bit=load_in_4bit,\n",
        ")\n"
      ],
      "metadata": {
        "id": "ZlYr6wdSxelL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# 3. Apply LoRA\n",
        "# =========================\n",
        "model = FastLanguageModel.get_peft_model(\n",
        "    model,\n",
        "    r=32,\n",
        "    target_modules=[\n",
        "        \"q_proj\",\"k_proj\",\"v_proj\",\"o_proj\",\n",
        "        \"gate_proj\",\"up_proj\",\"down_proj\"\n",
        "    ],\n",
        "    lora_alpha=32,\n",
        "    lora_dropout=0,\n",
        "    bias=\"none\",\n",
        "    use_gradient_checkpointing=False,\n",
        "    random_state=3407,\n",
        ")\n"
      ],
      "metadata": {
        "id": "DM-pEdG3xgHH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# 4. Dataset Preparation\n",
        "# =========================\n",
        "alpaca_prompt = \"\"\"Below is an instruction...\n",
        "\n",
        "### Instruction:\n",
        "{}\n",
        "\n",
        "### Input:\n",
        "{}\n",
        "\n",
        "### Response:\n",
        "{}\"\"\"\n",
        "\n",
        "EOS_TOKEN = tokenizer.eos_token\n",
        "\n",
        "def format_data(examples):\n",
        "    texts = []\n",
        "    for i, inp, out in zip(\n",
        "        examples[\"instruction\"],\n",
        "        examples[\"input\"],\n",
        "        examples[\"output\"]\n",
        "    ):\n",
        "        texts.append(alpaca_prompt.format(i, inp, out) + EOS_TOKEN)\n",
        "    return {\"text\": texts}\n",
        "\n",
        "dataset = load_dataset(\"yahma/alpaca-cleaned\", split=\"train\")\n",
        "dataset = dataset.map(format_data, batched=True)\n"
      ],
      "metadata": {
        "id": "saQ_uTvMxh9b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# 5. Training\n",
        "# =========================\n",
        "trainer = SFTTrainer(\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    train_dataset=dataset,\n",
        "    dataset_text_field=\"text\",\n",
        "    packing=True,\n",
        "    args=SFTConfig(\n",
        "        per_device_train_batch_size=2,\n",
        "        gradient_accumulation_steps=4,\n",
        "        num_train_epochs=1,\n",
        "        learning_rate=2e-5,\n",
        "        optim=\"adamw_8bit\",\n",
        "        output_dir=\"outputs\",\n",
        "        report_to=\"none\",\n",
        "    ),\n",
        ")\n",
        "\n",
        "trainer.train()\n"
      ],
      "metadata": {
        "id": "bcL3bMvKxjC3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# 6. Inference\n",
        "# =========================\n",
        "FastLanguageModel.for_inference(model)\n",
        "\n",
        "inputs = tokenizer(\n",
        "    alpaca_prompt.format(\n",
        "        \"Continue the Fibonacci sequence\",\n",
        "        \"1, 1, 2, 3, 5, 8\",\n",
        "        \"\"\n",
        "    ),\n",
        "    return_tensors=\"pt\"\n",
        ").to(\"cuda\")\n",
        "\n",
        "outputs = model.generate(**inputs, max_new_tokens=64)\n",
        "print(tokenizer.decode(outputs[0], skip_special_tokens=True))\n"
      ],
      "metadata": {
        "id": "Tg8PzBaIxkPb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# 7. Save LoRA\n",
        "# =========================\n",
        "model.save_pretrained(\"lora_model\")\n",
        "tokenizer.save_pretrained(\"lora_model\")"
      ],
      "metadata": {
        "id": "Wy1BzkOlxlX0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}